{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEl8taNDy4Ju"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U72ULHQKzw8B"
   },
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3J7vaA5zODI"
   },
   "outputs": [],
   "source": [
    "file_path= 'dataset_merged_iberlef.csv'\n",
    "df= pd.read_csv(file_path)\n",
    "# Filter by train dataset\n",
    "train_df = df[df['source'] == 'train']\n",
    "# Filter by dev dataset\n",
    "dev_df = df[df['source'] == 'dev']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22B1sQyqz1f7"
   },
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsrAG0qRz0hP"
   },
   "outputs": [],
   "source": [
    "target_names= ['0','1', '2', '3','4']\n",
    "class_names= ['Not Hope','Generalized Hope', 'Realistic Hope','Unrealistic Hope', 'Sarcasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZOomvtjz6Lx"
   },
   "outputs": [],
   "source": [
    "def map_label(row):\n",
    "    if row['multiclass']=='Not Hope':\n",
    "        return 0\n",
    "    elif row['multiclass']=='Generalized Hope':\n",
    "        return 1\n",
    "    elif row['multiclass']=='Realistic Hope':\n",
    "        return 2\n",
    "    elif row['multiclass']=='Unrealistic Hope':\n",
    "        return 3\n",
    "    elif row['multiclass']=='Sarcasm':\n",
    "        return 4\n",
    "\n",
    "train_df = train_df.assign(label= train_df.apply(map_label, axis=1))\n",
    "dev_df = dev_df.assign(label= dev_df.apply(map_label, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9YgJx70z8aY"
   },
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "\n",
    "from simpletransformers.classification import (\n",
    "    MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    ")\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5rRQLkF0WB7"
   },
   "outputs": [],
   "source": [
    "def run_ModelTransformer(transformermodel, train, test, _target_names=[], _class_names=[]):\n",
    "    # Create training data in the correct format for SimpleTransformers\n",
    "    train_df = pd.DataFrame({\n",
    "        'text': train['clean_text'],\n",
    "        'labels': train['label']\n",
    "    })\n",
    "\n",
    "    # Ensure labels are integers (needed for SimpleTransformers)\n",
    "    train_df['labels'] = train_df['labels'].astype(int)\n",
    "\n",
    "    # For unlabeled test data, create a DataFrame with just the text\n",
    "    test_df = pd.DataFrame({\n",
    "        'text': test['clean_text']\n",
    "    })\n",
    "\n",
    "\n",
    "    # Create a TransformerModel\n",
    "    model = ClassificationModel(\n",
    "        transformermodel[0],\n",
    "        transformermodel[1],\n",
    "        num_labels=5,\n",
    "        use_cuda=True,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        args={\n",
    "            'num_train_epochs': 1,\n",
    "            'learning_rate': 1e-5,\n",
    "            'max_seq_length': 64,\n",
    "            'use_multiprocessing': False,\n",
    "            'use_multiprocessing_for_evaluation': False,\n",
    "            'overwrite_output_dir': True\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Train the model with the properly formatted DataFrame\n",
    "    model.train_model(train_df)\n",
    "\n",
    "    # Using predict method\n",
    "    predictions, raw_outputs = model.predict(test_df['text'].tolist())\n",
    "\n",
    "    # Save predictions to the original test DataFrame and export\n",
    "    test['predicted'] = predictions\n",
    "    test.to_csv('predictions_multiclass_iberlef.csv', index=None)\n",
    "\n",
    "    # Output information about the prediction process\n",
    "    print(\"Predictions completed\")\n",
    "    print(f\"Predicted {len(predictions)} samples.\")\n",
    "\n",
    "    # Return the predictions\n",
    "    return {\n",
    "        'predictions': predictions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660,
     "referenced_widgets": [
      "7dd4bd4305bb4735bf776180612769e4",
      "33ee217ae14e4dd4901744f9edf5d28e",
      "9d820a0561384ff9a16831aefb238606",
      "0cf002423cf94c9cbafe8c5d22d4ed8c",
      "c828510bc85d4972a861db55322814f5",
      "b19f1450c152471f958b48c6c095906e",
      "90967ad51f6443d0a3b73718e7656001",
      "442b907d27e14f62993a23dd9416f602",
      "e0f9cce9aca74cbba17bf4149a261e12",
      "522f32e4a3e84f62b84e11dabc119783",
      "a7250f5749194116bf45c7d42af518e3",
      "8461cbb729fb4544b84d11accdc67643",
      "30f15c0d23f74f0fb864e36857c10f7f",
      "6a7fdddfa3cb4d229f54124194c7adf2",
      "0da4bada33ae4217a40dc64d7de11b24",
      "740f74f027784a468b7fdbd222f4c592",
      "5e7b6caff671487b9b01e8335c139e0d",
      "61452dfad7f34eeb8d69a5f2f3782f64",
      "bf01786f2c674fc68c092b0360252767",
      "16bea34d2743483ab1a6957b47fd154c",
      "54f75d2ddb334a12981caed522aef410",
      "d0c4629eacb345a7899d349a1b33c58a",
      "a58d8f67852a449e99c1d09f70c07701",
      "c7e5a02520c04410908534a894ce66e5",
      "64595adfcec9446c872609381b005391",
      "97430382a7894e75b73e6094d96ada4b",
      "568a18e5f85940fda7ea169482eb84aa",
      "1ec9a13585d84fed92d790bf26b9b04a",
      "6e0b1822c1504e1a879c33cbb2f8fa47",
      "cbec5c7cda76400a87cee5e9a870112d",
      "f2f2b37ab10e443180488475b02bba9f",
      "b11ed26abccc4eac8d21fc74819cd9b0",
      "c1e3649c5064479dadd856a3ca5f0417",
      "510f0d9a622c4e0085b7002a6e1c9948",
      "71fa9d6d7ad94c89b361624365bfc170",
      "bac183ae834d4a4fac9caaefe7fbd01b",
      "3fe394f7583b4adf898a274ab68d7169",
      "3714d97c9e0949bdb30b38cbbe124a53",
      "a18b45cc00e6422cbec68bfb1ad2483e",
      "371c9d747ad349ff9b587f03b31cb6b4",
      "3e6fe37ff1304f72b446cf433e580dba",
      "2ec583ce1e7248b98cbf45b23f1e1d9b",
      "611c6d1f0d9742cfa2a204961f0082fc",
      "50e8109daa12404fb498fb1d3007a6bd",
      "3848c4f797ed4e51be8f6f830ce43859",
      "44c5d5e5f70a485ba0fcd9c63caf58a6",
      "451d6f0b52104631bce78af13aa4fc24",
      "97448c6394324306b4f6315656762ec8",
      "86f155d03d7141bbb7ac3ceb812d5f1b",
      "c51d9e27abd54f3588c638dc4b554730",
      "54a5ec2327644158afbc3bcd40755ff2",
      "05ffa7d67f554ea6882adae723b56f2c",
      "107790eca71a4a5393b03b340ef7414c",
      "dd0ed4a85441433086ac49c30e715e20",
      "0503430518c2424699dec87abc7b0cfc",
      "2ed5a5bb556743cca077dd425282aa0a",
      "2535f4f3742f4849bc47a06b797dc59e",
      "99166e332431423085a319c891ec4b25",
      "8d41197489ff49548af25a6be195f4a7",
      "a7aef655f3954145aa3a48e7d9f3ac99",
      "41d744c390104251aaafd9bc483c1278",
      "53771308c2144dcba2d1f112d37bf8d8",
      "17c5a75daf5e42c58e6cbf361ce6a47d",
      "142392a98bca4475b293289879bc7761",
      "50168d493d06438293e88783607f93d8",
      "83f643a23470460f84372e24c70ce1a0",
      "b97fd74b1281416487514d00a7863845",
      "78703b25d5484bbd990c7ae03d17b074",
      "b6fe8edf328841b1890744e18230f59d",
      "2e0bd1aaef5b4dc49d2314d4b7d9a70c",
      "46d7cb935c154e49a4f4f041bea36f74",
      "df0f10926a69473ea8223556ee2cddcb",
      "e30ae2603b0447debeaf58bec38e36da",
      "c99f77e2c5104c08a9b1180241dd3ed9",
      "c28517c8776f433790a72141393ec1ae",
      "f7590f565b9c4c55a8ec7d7b4caa5e48",
      "2c5a0695996b47179cb6868078c64f7a"
     ]
    },
    "executionInfo": {
     "elapsed": 527644,
     "status": "ok",
     "timestamp": 1745455613227,
     "user": {
      "displayName": "Diana Madera",
      "userId": "02874740717861520266"
     },
     "user_tz": 360
    },
    "id": "WApXT6ZJ0ZKo",
    "outputId": "0beae7a4-7c04-41b1-ae60-fcfd64b4175d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd4bd4305bb4735bf776180612769e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8461cbb729fb4544b84d11accdc67643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58d8f67852a449e99c1d09f70c07701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510f0d9a622c4e0085b7002a6e1c9948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLMRobertaTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3848c4f797ed4e51be8f6f830ce43859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/simpletransformers/classification/classification_model.py:882: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed5a5bb556743cca077dd425282aa0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 1:   0%|          | 0/2661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/simpletransformers/classification/classification_model.py:905: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97fd74b1281416487514d00a7863845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/simpletransformers/classification/classification_model.py:2188: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions completed for unlabeled test data.\n",
      "Predicted 5990 samples.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': array([0, 2, 2, ..., 0, 2, 0])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ModelTransformer(['roberta', 'xlm-roberta-base'],train_df, dev_df, target_names, class_names)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}